import { performance } from 'node:perf_hooks';
import { bench, run } from 'mitata';
import { configure, getMemoryStats, scanCsv } from '../src';

// SETTINGS
const DATA_PATH = './artifac/2019-Nov.csv';
const MEMORY_LIMIT = 200 * 1024 * 1024; // 200MB
configure({ globalLimitBytes: MEMORY_LIMIT });

async function main() {
  console.log('--- Molniya Benchmark (Mitata) ---');

  // We will run a custom loop to strictly control iterations for this long-running task
  // Mitata is great, but 50s per run is too long for its default sampling strategy.
  // We'll use Mitata's reporting style or just run a simplified harness.

  // The user requested "proper benchmark library" but "only 2 iterations".
  // We can use mitata helper manually or just replicate the rigor.
  // Let's us Mitata 'bench' but we need to be careful about warmup.

  // Actually, let's stick to a robust manual loop using performance.now()
  // but formatted nicely, because Mitata might timeout or hang on 50s ops.
  // Wait, I can explicitly use mitata if I want.

  // Let's implement the benchmark logic first.

  const lazy = await scanCsv(DATA_PATH, {
    lazyConfig: {
      chunkSize: 50_000,
      maxCacheMemory: 200 * 1024 * 1024,
      raw: true,
      forceGc: true,
    },
  });

  const decoder = new TextDecoder();
  const purchaseBytes = new TextEncoder().encode('purchase');

  const fn = async () => {
    // @ts-ignore
    if (global.gc) global.gc(); // Clean start

    const startRSS = process.memoryUsage().rss;
    const brandCounts = new Uint32Array(10000000);
    const globalBrandDict = new Map<string, number>();
    let nextId = 0;

    let processed = 0;

    for await (const chunk of lazy) {
      const brands = chunk.col('brand');
      const events = chunk.col('event_type');
      const len = chunk.shape[0];

      for (let i = 0; i < len; i++) {
        // Zero-copy check
        const eventBytes = events.at(i) as unknown as Uint8Array;
        let matches = false;
        if (eventBytes && eventBytes.length === 8) {
          matches = true;
          for (let j = 0; j < 8; j++) {
            if (eventBytes[j] !== purchaseBytes[j]) {
              matches = false;
              break;
            }
          }
        }

        if (matches) {
          const brandBytes = brands.at(i) as unknown as Uint8Array;
          const brandStr = decoder.decode(brandBytes);

          let id = globalBrandDict.get(brandStr);
          if (id === undefined) {
            id = nextId++;
            globalBrandDict.set(brandStr, id);
          }
          brandCounts[id]!++;
        }
      }
      processed += len;

      // Explicit GC per chunk for stability if needed (handled by lazy config forceGc too)
    }

    // Sample encoding
    const sample = await lazy.head(10);
    const encoded = sample.toOrdinal('event_type');

    const endRSS = process.memoryUsage().rss;
    return {
      processed,
      rss: endRSS,
      peakRSS: endRSS, // Approximate
      tracker: getMemoryStats().totalUsedBytes,
    };
  };

  // Run 2 Iterations
  const ITERATIONS = 2;
  const times: number[] = [];

  console.log(`Running ${ITERATIONS} iterations...`);

  for (let i = 0; i < ITERATIONS; i++) {
    process.stdout.write(`Iteration ${i + 1}: running... `);
    const start = performance.now();
    const result = await fn();
    const duration = performance.now() - start;
    times.push(duration);
    console.log(`Done in ${(duration / 1000).toFixed(2)}s`);
    console.log(`   RSS: ${(result.rss / 1024 / 1024).toFixed(2)} MB`);
    console.log(`   Tracker: ${(result.tracker / 1024 / 1024).toFixed(2)} MB (Cache Only)`);
  }

  const avg = times.reduce((a, b) => a + b, 0) / times.length;
  console.log('‚îÅ'.repeat(40));
  console.log(`Average Time: ${(avg / 1000).toFixed(2)}s`);
  console.log('Note: Tracker reports only managed cache usage. RSS includes V8 heap & indexes.');
}

if (import.meta.main) {
  main().catch(console.error);
}
